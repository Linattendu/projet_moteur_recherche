import pandas as pd
import pickle
from datetime import datetime
import re
from src.Author import Author
from src.Frequence import Frequence 
from src.Utils import Utils
import uuid  # Pour g√©n√©rer des identifiants uniques


class Corpus:
    """
    @class Corpus
    @brief Repr√©sente un corpus de documents avec diverses fonctionnalit√©s de recherche et d'analyse.
    """
    def __init__(self, nom_corpus=None, theme=None):
        """
        @brief Initialise un nouveau corpus.
        @param nom_corpus Nom du corpus (par d√©faut None).
        @param theme Th√®me par d√©faut des documents dans le corpus.
        """
        self.nom_corpus = nom_corpus
        self.authors = {}
        
        # dictionnaire d‚Äôindices id2doc dont les cl√©s sont les identifiants et les valeurs
        # les objets qui repr√©sentent les documents. {"id":"doc"}
        self.id2doc = {} # 
        self.ndoc = 0
        self.naut = 0
        self.texte_concatene = None  
        self.theme = theme
        
    def ajouter_document(self, doc):
        """
        @brief Ajoute un document au corpus.
        @param doc Instance du document √† ajouter.
        @return True si le document est ajout√©, False sinon.
        """        
        
        identifiant_unique = str(uuid.uuid4())  # G√©n√©ration d'un identifiant unique (UUID)
        
        doc.texte = Utils.nettoyer_texte(doc.texte)  # Nettoyage du texte avant ajout
        
         # V√©rification de l'unicit√©
        if identifiant_unique in self.id2doc:
            print(f"‚ö†Ô∏è Document d√©j√† existant : {identifiant_unique}")
            return False
        
        # Ajouter le document avec l'ID g√©n√©r√©
        self.id2doc[identifiant_unique] = doc
        self.ndoc += 1

        # G√©rer l'auteur
        auteur_nom = doc.auteur.lower()
        if auteur_nom not in self.authors:
            self.authors[auteur_nom] = Author(auteur_nom)
            self.naut += 1
        
        self.authors[auteur_nom].add(identifiant_unique, doc)
        
       
        if doc.theme is None:
            doc.theme = self.theme  # Utilisation du th√®me du corpus par d√©faut
        
        
        return True

    def search(self, mot_cle):
        """
        @brief Recherche des passages contenant un mot-cl√© dans le texte concat√©n√© du corpus.
        @param mot_cle Mot-cl√© √† rechercher.
        @return Liste des passages contenant le mot-cl√© ou un message indiquant qu'aucun r√©sultat n'a √©t√© trouv√©.
        """
        # V√©rification et concat√©nation automatique si n√©cessaire
        if not self.texte_concatene:
            #print("üîÑ Concat√©nation automatique du corpus...")
            self.texte_concatene = Utils.concatener_textes(self)
        
        # Regex : capturer 4 mots avant et apr√®s le mot-cl√©
        pattern = rf'(\b\w+(?:\s+\w+){{0,3}}\s+)\b{re.escape(mot_cle.lower())}\b(\s+\w+(?:\s+\w+){{0,3}})'

        
        passages = re.findall(pattern, self.texte_concatene)

        # Si aucun passage trouv√©
        if not passages:
            return ["Aucun r√©sultat trouv√©."]
        
        # Reconstituer les passages captur√©s
        resultats = [f"{p[0]}{mot_cle}{p[1]}" for p in passages]

        # Affichage pour contr√¥le
        """ for i,passage in enumerate(resultats):
            print(f"‚úÖ le passage {i + 1 } : {passage}\n") """

        return resultats


    def concorde(self, mot_cle, taille_contexte=30):
        """
        @brief G√©n√®re un concordancier pour un mot-cl√© donn√©.
        @param mot_cle Mot-cl√© √† rechercher.
        @param taille_contexte Nombre de caract√®res avant et apr√®s le mot-cl√© √† inclure dans le contexte.
        @return DataFrame contenant les contextes avant, apr√®s et le mot-cl√© trouv√©.
        """
        # V√©rification et concat√©nation automatique si n√©cessaire
        if not self.texte_concatene:
            #print("üîÑ Concat√©nation automatique du corpus...")
            self.texte_concatene = Utils.concatener_textes(self)
            
        occurences = list(re.finditer(re.escape(mot_cle), self.texte_concatene, re.IGNORECASE))

        contexte_avant = []
        mot_cle_trouve = []
        contexte_apres = []

        for occ in occurences:
            debut, fin = occ.start(), occ.end()
            mot_cle_trouve.append(self.texte_concatene[debut:fin])

            debut_contexte = max(0, debut - taille_contexte)
            contexte_avant.append(self.texte_concatene[debut_contexte:debut])

            fin_contexte = min(len(self.texte_concatene), fin + taille_contexte)
            contexte_apres.append(self.texte_concatene[fin:fin_contexte])

        df = pd.DataFrame({
            'contexte_avant': contexte_avant,
            'mot_cle_trouve': mot_cle_trouve,
            'contexte_apres': contexte_apres
        })
        return df
    
    def afficher_premiers_documents(self, n=5):
        """
        @brief Affiche les n premiers documents du corpus.
        @param n Nombre de documents √† afficher (par d√©faut 5).
        """
        print(f"\nüìÑ Affichage des {n} premiers documents du corpus :\n")
        for i, doc in enumerate(list(self.id2doc.values())[:n]):
            print(f"üîπ Document {i+1} :")
            print(f"   Titre : {doc.titre}")
            print(f"   Auteur : {doc.auteur}")
            print(f"   Date : {doc.date}")
            print(f"   URL : {doc.url}")
            print(f"   Contenu : {doc.texte}")  # Affiche seulement les 200 premiers caract√®res
            print("-" * 80)

    
    def stats(self, n=10):
        """
        @brief Renvoie les n mots les plus fr√©quents dans le corpus.
        @param n Nombre de mots les plus fr√©quents √† retourner (par d√©faut 10).
        @return DataFrame contenant les mots et leur fr√©quence.
        """
        compteur = Frequence.compter_occurrences(self.id2doc.values())
        freq_df = pd.DataFrame(compteur.most_common(n), columns=['Mot', 'Fr√©quence'])
        return freq_df
    
    def trier_par_date(self, n=10):
        """
        @brief Trie les documents par date de publication.
        @param n Nombre de documents √† retourner (par d√©faut 10).
        @return Liste des n documents les plus r√©cents.
        """
        return sorted(self.id2doc.values(), key=lambda d: d.date, reverse=True)[:n]

    def trier_par_titre(self, n=10):
        """
        @brief Trie les documents par titre alphab√©tique.
        @param n Nombre de documents √† retourner (par d√©faut 10).
        @return Liste des n premiers documents tri√©s par titre.
        """
        return sorted(self.id2doc.values(), key=lambda d: d.titre)[:n]

    def __repr__(self):
        """
        @brief Retourne une repr√©sentation textuelle du corpus.
        @return Cha√Æne repr√©sentant le corpus (nom, nombre de documents et auteurs).
        """
        return f"Nom du corpus: {self.nom_corpus} - {self.ndoc} documents, {self.naut} auteurs , Theme : {self.theme}"

    def save(self, path):
        """
        @brief Retourne une repr√©sentation textuelle du corpus.
        @return Cha√Æne repr√©sentant le corpus (nom, nombre de documents et auteurs).
        """
        with open(path, 'wb') as f:
            pickle.dump(self, f)

    @staticmethod
    def load(path):
        """
        @brief Charge un corpus √† partir d'un fichier pickle.
        @param path Chemin du fichier de sauvegarde.
        @return Instance de Corpus charg√©e.
        """
        with open(path, 'rb') as f:
            return pickle.load(f)
    

if __name__ == "__main__":
    from src.Document import Document
    
    corpus = Corpus("water")
    corpus.ajouter_document(Document("Doc1", "Auteur1", datetime.now(), "url1", 
                                     "Monitoring water quality is essential for ecosystems, ensuring the survival of aquatic life and maintaining biodiversity. By preventing pollution and detecting harmful substances early, environmental agencies can protect rivers, lakes, and oceans, preserving delicate habitats and supporting local communities that rely on these ecosystems."))
    
    corpus.ajouter_document(Document("Doc2", "Auteur2", datetime.now(), "url2", 
                                     "The preservation of water resources helps prevent droughts by enhancing groundwater recharge and promoting efficient water usage. Conservation efforts, such as reforestation and wetland restoration, play a critical role in mitigating the impacts of climate change, safeguarding future water supplies for both human populations and natural environments."))
    
    corpus.ajouter_document(Document("Doc3", "Auteur3", datetime.now(), "url3", 
                                     "Water resources are vital for agriculture, providing essential irrigation to crops and sustaining livestock. Without sufficient water, food production can significantly decline, leading to shortages and economic instability in rural communities."))

    # test de search
    reustlat_search = corpus.search("water")
    print("R√©sultat search : \n", reustlat_search)
    
    # Test Concorde
    resultat_concorde = corpus.concorde("resources", taille_contexte=10)
    print("R√©sultat concorde : \n", resultat_concorde)
    
    # Statistiques des mots
    df = corpus.stats(10)
    print("Statistiques : ", df)
    
   
